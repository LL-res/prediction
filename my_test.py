import data_preparation
import net
import math
import matplotlib.pyplot as plt

import param

metrics = []
start_predict_idex = 4000

for i in range(0,1000):
    metrics.append(100*math.sin(0.1*i))
tests = []
for i in range(start_predict_idex,start_predict_idex+param.look_back):
    tests.append(100*math.sin(0.1*i))
real = []
for i in range(start_predict_idex,start_predict_idex+param.look_back+param.look_forward):
    real.append(100*math.sin(0.1*i))
#train_loader = data_preparation.train_data_prepare(metrics)

#net.train(train_loader,"cpu")


out = net.predict(tests,"GRU","cpu")
print(out.tolist())
tests.extend(out.tolist()[0])

plt.plot(tests)

plt.plot(real)
plt.show()

import net
import matplotlib.pyplot as plt
data = [0.4121184852417566,0.40298672872464775,0.39381467387048763,0.38460323787711825,0.37535334188046116,0.366065910862411,0.3567418735583286,0.34738216236417424,0.33798771324326765,0.32855946563269217,0.3190983623493521,0.3096053494956915,0.3000813763650833,0.2905273953469072,0.2809443618313018,0.27133323411363275,0.26169497329866265,0.25203054320444107,0.24234091026592378,0.23262704343833002,0.22288991410024592,0.2131304959564945,0.20334976494075557,0.19354869911798014,0.18372827858658297,0.17388948538043356,0.16403330337065347,0.15416071816723032,0.14427271702045727,0.13437028872220727,0.12445442350706169,0.11452611295327708,0.10458634988363524,0.09463612826616005,0.08467644311472142,0.07470829038953478,0.06473266689756589,0.05475057019284918,0.04476299847674028,0.03477095049808608,0.024775425453357765,0.014777422886730236,0.004777942590128512,-0.00522201549675062,-0.015221451386431741,-0.025219365143660497,-0.03521475698538918,-0.04520662738076485,-0.05519397715107451,-0.0651758075696639,-0.07515112046180931,-0.08511891830453426,-0.09507820432636097,-0.10502798260698659,-0.11496725817687632,-0.12489503711675232,-0.1348103266569955,-0.14471213527691454,-0.15459947280389894,-0.16447135051243542,-0.17432678122297965,-0.1841647794006734,-0.19398436125389898,-0.20378454483265054,-0.2135643501267387,-0.2233227991637839,-0.2330589161070144,-0.24277172735284935,-0.2524602616282581,-0.26212355008788685,-0.2717606264109441,-0.28137052689782505,-0.2909522905664908,-0.30050495924855936,-0.310027577685123,-0.3195191936222736,-0.3289788579063271,-0.3384056245787381,-0.34779855097069495,-0.35715669779738757,-0.3664791292519284,-0.3757649130989423,-0.3850131207677826,-0.3942228274453894,-0.40339311216876955,-0.41252305791709265,-0.42161175170339216,-0.4306582846658648,-0.43966175215875003,-0.44862125384280294,-0.45753589377532133,-0.4664047804997409,-0.47522702713477977,-0.48400175146312646,-0.49272807601966023,-0.5014051281791989,-0.5100320402437544,-0.5186079495293108,-0.527131998452086,-0.5356033346142913]

out = net.predict(data,"fake$%$test_fake$gru")
data.extend(out.tolist()[0])
plt.plot(data)
plt.show()
print(out)


data = '''
{'trained': True, 'key': 'fake$%$test_fake$gru', 'prediction': [-0.5893626809120178, -0.5863917469978333, -0.6035324335098267, -0.609229326248169, -0.5929385423660278, -0.6214376091957092, -0.6183516979217529, -0.6441296935081482, -0.6472790837287903, -0.6832373142242432, -0.6481372117996216, -0.6462191939353943, -0.65919429063797, -0.6944029927253723, -0.6625329256057739, -0.673640787601471, -0.7074134349822998, -0.6981599926948547, -0.7068555355072021, -0.6761019825935364, -0.7235743403434753, -0.7186071872711182, -0.7200074195861816, -0.726624608039856, -0.7659124732017517, -0.7285388708114624, -0.7429609894752502, -0.7391539812088013, -0.7607994675636292, -0.7910709381103516, -0.7513635754585266, -0.7871445417404175, -0.8001407384872437, -0.7860966920852661, -0.8019434213638306, -0.7955658435821533, -0.8188796043395996, -0.8267537355422974, -0.8225056529045105, -0.7888386845588684, -0.8301430344581604, -0.8082312941551208, -0.8243814706802368, -0.8188154101371765, -0.8081262707710266, -0.8349667191505432, -0.8369824886322021, -0.8332107067108154, -0.8511587381362915, -0.8399356007575989, -0.8767401576042175, -0.875595211982727, -0.853746235370636, -0.864682137966156, -0.8700114488601685, -0.8622673749923706, -0.8539924025535583, -0.8955139517784119, -0.8898763060569763, -0.8536194562911987]}
'''

